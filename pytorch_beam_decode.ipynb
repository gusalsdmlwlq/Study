{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "hidden_size = 128\n",
    "vocab_size = 100\n",
    "max_len = 50\n",
    "pad_id = 0\n",
    "sos_id = 1\n",
    "eos_id = 2\n",
    "unk_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size, num_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = torch.nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "        self.linear = torch.nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs, encoder_hidden):\n",
    "        # inputs: [batch, time]\n",
    "        \n",
    "        output = self.embedding(inputs)\n",
    "        output, hidden = self.rnn(output, encoder_hidden)\n",
    "        output = self.linear(output)\n",
    "        output = F.softmax(output, dim=-1)\n",
    "        \n",
    "        # output: [batch, time, vocab]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(hidden_size, vocab_size, 1, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones([batch_size, 1], dtype=torch.int64)*sos_id\n",
    "x = decoder(x,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decode(decoder, encoder_hidden, beam_size, batch_size, max_len, sos_id, eos_id):\n",
    "    \"\"\"Beam search decoding.\n",
    "    \n",
    "    Args:\n",
    "        decoder: Pytorch RNN decoder.\n",
    "        encoder_hidden: Hidden state of RNN encoder.\n",
    "        beam_size: Beam width.\n",
    "        batch_size: Batch size.\n",
    "        max_len: Maximum steps of beam search.\n",
    "        sos_id: Id of <SOS>\n",
    "        eos_id: Id of <EOS>\n",
    "    \"\"\"\n",
    "    \n",
    "    # save k(=beam_size) paths\n",
    "    k_paths = [[[sos_id] for i in range(beam_size)] for j in range(batch_size)]\n",
    "    \n",
    "    # make <SOS> batch: [batch, 1]\n",
    "    sos_batch = torch.ones([batch_size, 1], dtype=torch.int64) * sos_id\n",
    "    \n",
    "    # outputs: [batch, vocab]\n",
    "    outputs = decoder(sos_batch, encoder_hidden)[:, -1, :]\n",
    "    \n",
    "    \"\"\"first step\"\"\"\n",
    "    for b, batch in enumerate(outputs):\n",
    "        # probs, preds: [beam_size]\n",
    "        probs, preds = torch.topk(batch, beam_size)\n",
    "        \n",
    "        for idx, pred in enumerate(preds):\n",
    "            k_paths[b][idx].append(pred.item())\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    for step in range(2, max_len+1):\n",
    "        # inputs: [batch, beam_size, step]\n",
    "        inputs = torch.LongTensor(k_paths)\n",
    "        # [batch, 1, step] * beam_size\n",
    "        inputs = torch.split(inputs, 1, dim=1)\n",
    "        \n",
    "        outputs = []\n",
    "        for inputs_ in inputs:\n",
    "            # inputs: [batch, step]\n",
    "            # output: [batch. vocab]\n",
    "            output = decoder(inputs_.view(batch_size, -1), encoder_hidden)[:, -1, :]\n",
    "            outputs.append(output)\n",
    "        \n",
    "        # outputs: [batch, vocab * beam_size]\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        for b, batch in enumerate(outputs):\n",
    "            probs, preds = torch.topk(batch, beam_size)\n",
    "            tmp_path = []\n",
    "            for idx, pred in enumerate(preds):\n",
    "                for i in range(beam_size):\n",
    "                    if pred >= i*vocab_size and pred < (i+1)*vocab_size:\n",
    "                        break\n",
    "                tmp_path.append(k_paths[b][i].copy())\n",
    "                tmp_path[idx].append(pred.item()-(i*100))\n",
    "            k_paths[b] = tmp_path\n",
    "            \n",
    "    return k_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 21, 67], [1, 65, 97], [1, 21, 60]]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_decode(decoder, None, 3, 4, 2, 1, 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
