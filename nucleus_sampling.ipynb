{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.embed_size = 100\n",
    "        self.vocab_size = 10000\n",
    "        self.embedding = torch.nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.num_layers = 1\n",
    "        self.encoder = torch.nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.decoder = torch.nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        self.max_len = 50\n",
    "        \n",
    "    def forward(self, inputs, mode=\"greedy\", k=0.0, p=0.0):\n",
    "        batch_size = inputs.size(0)\n",
    "        enc_inputs = self.embedding(inputs)  # [batch, time, embed]\n",
    "        enc_outputs, enc_hidden = self.encoder(enc_inputs)  # [batch, time, hidden], [layers, batch, hidden]\n",
    "        \n",
    "        dec_inputs = torch.ones(batch_size, 1, dtype=torch.int64).cuda()\n",
    "        dec_inputs = self.embedding(dec_inputs)  # [batch, 1, embed]\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        words = torch.zeros(batch_size, self.max_len, dtype=torch.int64).cuda()\n",
    "        for i in range(self.max_len):\n",
    "            dec_outputs, dec_hidden = self.decoder(dec_inputs, dec_hidden)  # [batch, 1, hidden], [layers, batch, hidden]\n",
    "            logits = self.linear(dec_outputs.squeeze(dim=1))  # [batch, vocab]\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            if mode == \"greedy\":\n",
    "                word = probs.argmax(dim=1).unsqueeze(dim=1)  # [batch, 1]\n",
    "            elif mode == \"sampling\":\n",
    "                if k > 0:\n",
    "                    mask = probs < torch.topk(probs, k)[0][:, -1].unsqueeze(dim=1)\n",
    "                    probs.masked_fill_(mask, value=0)\n",
    "                if p > 0:\n",
    "                    for batch_idx in range(batch_size):\n",
    "                        sorted_probs, sorted_idx = torch.sort(probs[batch_idx], descending=True)  # [vocab], [vocab]\n",
    "                        cumulative_probs = torch.cumsum(sorted_probs, dim=0)\n",
    "                        sorted_mask = cumulative_probs > p\n",
    "                        mask = sorted_idx[sorted_mask]\n",
    "                        probs[batch_idx, mask]=0\n",
    "                word = torch.multinomial(probs, 1)  # [batch, 1]\n",
    "            words[:, i] = word.squeeze(dim=1)\n",
    "            dec_inputs = self.embedding(word)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6628, 5233, 6492, 4255, 1482, 2146, 8036, 2416, 1373, 4443, 9263, 8254,\n",
       "         3566, 9409, 9409, 8028, 5183, 2269, 1871, 1484, 6148, 7053, 4691, 9415,\n",
       "         9817, 1629, 5890, 9428,  703, 3509, 5231, 5125, 7913, 4551, 7514, 7109,\n",
       "         2209, 3221, 8583, 5308,  973, 9249, 3997, 3557, 2969, 3763, 1145, 6121,\n",
       "         2779, 6091],\n",
       "        [6628, 5233, 6492, 4255, 1482, 2146, 8036, 2416, 1373, 4443, 9263, 8254,\n",
       "         3566, 9409, 9409, 8028, 5183, 2269, 1871, 1484, 6148, 7053, 4691, 9415,\n",
       "         9817, 1629, 5890, 9428,  703, 3509, 5231, 5125, 7913, 4551, 7514, 7109,\n",
       "         2209, 3221, 8583, 5308,  973, 9249, 3997, 3557, 2969, 3763, 1145, 6121,\n",
       "         2779, 6091],\n",
       "        [6628, 5233, 6492, 4255, 1482, 2146, 8036, 2416, 1373, 4443, 9263, 8254,\n",
       "         3566, 9409, 9409, 8028, 5183, 2269, 1871, 1484, 6148, 7053, 4691, 9415,\n",
       "         9817, 1629, 5890, 9428,  703, 3509, 5231, 5125, 7913, 4551, 7514, 7109,\n",
       "         2209, 3221, 8583, 5308,  973, 9249, 3997, 3557, 2969, 3763, 1145, 6121,\n",
       "         2779, 6091],\n",
       "        [6628, 5233, 6492, 4255, 1482, 2146, 8036, 2416, 1373, 4443, 9263, 8254,\n",
       "         3566, 9409, 9409, 8028, 5183, 2269, 1871, 1484, 6148, 7053, 4691, 9415,\n",
       "         9817, 1629, 5890, 9428,  703, 3509, 5231, 5125, 7913, 4551, 7514, 7109,\n",
       "         2209, 3221, 8583, 5308,  973, 9249, 3997, 3557, 2969, 3763, 1145, 6121,\n",
       "         2779, 6091]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.ones(4, 10, dtype=torch.int64).cuda()\n",
    "outputs = model(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5233, 7811, 9159, 1482, 5882, 8415, 9110, 7950, 4632, 4275, 9847, 1525,\n",
       "         7183, 8251, 9009, 4828, 5477, 8014, 8973, 3923, 6916, 1713, 6828, 8285,\n",
       "         7973, 4134, 1063, 5935,  626, 6078, 4866, 7212, 8295, 1616, 3929, 7500,\n",
       "         7765, 1509, 1241, 7377, 3263,  936,  980, 6111, 5454, 9448, 7852, 2390,\n",
       "         7260, 8526],\n",
       "        [8221, 7499, 4755,  929, 4816, 1713, 7582, 8919, 6186, 2105, 2768, 5288,\n",
       "         9947, 3952,  105,  346, 4015, 8280, 8040, 2675, 6619,   79, 3695,  525,\n",
       "         1969, 4604, 9559, 6252,  107, 1573, 8099, 1651,  116, 7311, 1828, 9284,\n",
       "         1899, 2604, 1195, 5592, 9350, 4028, 2160, 3818, 7851, 9454, 6872, 9239,\n",
       "         2572, 6228],\n",
       "        [ 851, 6819, 3388, 8546, 9038, 7900, 7851, 2439, 3499, 8768, 5403, 3830,\n",
       "          876, 4731, 9415, 1482, 8031, 2890, 7414, 6852, 1142, 6508, 6291, 2798,\n",
       "         2837, 5031, 8539, 7456, 5742, 5152, 9658, 7907, 5945, 4788, 9557, 8215,\n",
       "         9197, 6659, 8297, 2179, 1450, 6737, 3368, 8274, 9237, 4597, 7941, 9990,\n",
       "          265, 9679],\n",
       "        [8992, 1665, 5612, 6275, 7509, 6508,  290, 2908, 4381, 9955, 6307, 1223,\n",
       "         2465, 3763,  317, 1164, 3063, 5267, 4499,  897, 1417, 8859, 9995, 9377,\n",
       "         6865, 4915, 9310, 6921, 8380, 1050, 6907, 5882,  520, 8201, 3163, 4641,\n",
       "         1202, 9377, 8054, 4623, 1611, 1572, 5023, 1423, 8981, 1370,  362, 7939,\n",
       "         5371,  424]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.ones(4, 10, dtype=torch.int64).cuda()\n",
    "outputs = model(inputs, mode=\"sampling\", k=30, p=0.9)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
