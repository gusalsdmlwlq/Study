{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.hidden_size = 100\n",
    "        self.embed_size = 100\n",
    "        self.vocab_size = 10000\n",
    "        self.embedding = torch.nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.num_layers = 1\n",
    "        self.encoder = torch.nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.decoder = torch.nn.GRU(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        self.max_len = 50\n",
    "        \n",
    "    def forward(self, inputs, mode=\"greedy\", k=0.0, p=0.0):\n",
    "        batch_size = inputs.size(0)\n",
    "        enc_inputs = self.embedding(inputs)  # [batch, time, embed]\n",
    "        enc_outputs, enc_hidden = self.encoder(enc_inputs)  # [batch, time, hidden], [layers, batch, hidden]\n",
    "        \n",
    "        dec_inputs = torch.ones(batch_size, 1, dtype=torch.int64)\n",
    "        dec_inputs = self.embedding(dec_inputs)  # [batch, 1, embed]\n",
    "        dec_hidden = enc_hidden\n",
    "        \n",
    "        words = torch.zeros(batch_size, self.max_len, dtype=torch.int64)\n",
    "        for i in range(self.max_len):\n",
    "            dec_outputs, dec_hidden = self.decoder(dec_inputs, dec_hidden)  # [batch, 1, hidden], [layers, batch, hidden]\n",
    "            logits = self.linear(dec_outputs.squeeze(dim=1))  # [batch, vocab]\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            if mode == \"greedy\":\n",
    "                word = probs.argmax(dim=1).unsqueeze(dim=1)  # [batch, 1]\n",
    "            elif mode == \"sampling\":\n",
    "                if k > 0:\n",
    "                    mask = probs < torch.topk(probs, k)[0][:, -1].unsqueeze(dim=1)\n",
    "                    probs.masked_fill_(mask, value=0)\n",
    "                if p > 0:\n",
    "                    for batch_idx in range(batch_size):\n",
    "                        sorted_probs, sorted_idx = torch.sort(probs[batch_idx], descending=True)  # [vocab], [vocab]\n",
    "                        cumulative_probs = torch.cumsum(sorted_probs, dim=0)\n",
    "                        sorted_mask = cumulative_probs > p\n",
    "                        mask = sorted_idx[sorted_mask]\n",
    "                        probs[batch_idx, mask]=0\n",
    "                word = torch.multinomial(probs, 1)  # [batch, 1]\n",
    "            words[:, i] = word.squeeze(dim=1)\n",
    "            dec_inputs = self.embedding(word)\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1941, 4321, 2671, 9853, 6813, 6510, 3636, 5522, 2278, 3361, 7396, 8294,\n",
       "         3754,  120, 2268, 9773, 3785,  911, 9538,  911, 9538, 6668, 5420, 1204,\n",
       "         5189, 2923, 9549, 8157, 1542, 5776, 6392, 7061, 3878, 8643, 5594, 2471,\n",
       "         6618, 4434, 7196, 9222, 1728, 1396, 5829, 5592, 4174, 6464, 2603, 6286,\n",
       "         5156, 1282],\n",
       "        [1941, 4321, 2671, 9853, 6813, 6510, 3636, 5522, 2278, 3361, 7396, 8294,\n",
       "         3754,  120, 2268, 9773, 3785,  911, 9538,  911, 9538, 6668, 5420, 1204,\n",
       "         5189, 2923, 9549, 8157, 1542, 5776, 6392, 7061, 3878, 8643, 5594, 2471,\n",
       "         6618, 4434, 7196, 9222, 1728, 1396, 5829, 5592, 4174, 6464, 2603, 6286,\n",
       "         5156, 1282],\n",
       "        [1941, 4321, 2671, 9853, 6813, 6510, 3636, 5522, 2278, 3361, 7396, 8294,\n",
       "         3754,  120, 2268, 9773, 3785,  911, 9538,  911, 9538, 6668, 5420, 1204,\n",
       "         5189, 2923, 9549, 8157, 1542, 5776, 6392, 7061, 3878, 8643, 5594, 2471,\n",
       "         6618, 4434, 7196, 9222, 1728, 1396, 5829, 5592, 4174, 6464, 2603, 6286,\n",
       "         5156, 1282],\n",
       "        [1941, 4321, 2671, 9853, 6813, 6510, 3636, 5522, 2278, 3361, 7396, 8294,\n",
       "         3754,  120, 2268, 9773, 3785,  911, 9538,  911, 9538, 6668, 5420, 1204,\n",
       "         5189, 2923, 9549, 8157, 1542, 5776, 6392, 7061, 3878, 8643, 5594, 2471,\n",
       "         6618, 4434, 7196, 9222, 1728, 1396, 5829, 5592, 4174, 6464, 2603, 6286,\n",
       "         5156, 1282]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.ones(4, 10, dtype=torch.int64)\n",
    "outputs = model(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9245, 9595, 7072, 5389, 7098, 2671, 3199, 7919, 3396, 6590, 8866, 4545,\n",
       "         2285, 5052, 1502, 1724, 9764, 2592, 9765, 3730, 6967, 5363, 4635, 3270,\n",
       "         4952, 9021, 2268, 5972,   57, 5420, 3545, 5910, 7632, 7038, 4979, 5048,\n",
       "         2780, 8297, 6278, 6911, 3683, 4185, 2725, 4585, 6984, 3392, 9630, 4950,\n",
       "         1157, 8340],\n",
       "        [1399,  782,  566, 4068, 8798, 1054, 5087, 2784, 2331, 8797, 7428, 3831,\n",
       "         7227, 4632, 3342, 8588, 5772, 8160,  994, 4039, 3533,  772, 4374, 8502,\n",
       "         3707, 5753, 9286, 9877, 6536, 9336, 9633, 7431, 4837, 3408, 2170, 1708,\n",
       "         1654, 4098,  417, 9155, 9969, 7112, 1009, 3976, 1289, 3125, 3081, 4943,\n",
       "         1579, 5886],\n",
       "        [4373, 7027, 7633, 3735, 9280, 5309, 6678, 1673, 1654, 6281, 9623, 9369,\n",
       "         5725, 2552, 2943, 1820,  452, 9528, 9397, 9778, 2565, 9445, 1131, 9981,\n",
       "         9029, 2307, 7747, 6292, 2565, 1723, 9353, 7695, 5495, 4891, 6821, 4496,\n",
       "         6620, 2036, 7785, 4776, 6389, 4908, 7725, 7706, 7756, 6405, 9502, 2911,\n",
       "         3245, 1556],\n",
       "        [3785, 6640, 2633, 8067, 5052, 3840, 1201, 5460,  473,  258, 9981, 5390,\n",
       "         7566, 3028, 8246,  251, 4315, 1233, 3016, 9853, 9297, 4788, 6178, 8908,\n",
       "         3155, 4810, 4318, 9953, 4402, 5053, 6035, 6782, 8301, 3504, 6518, 6244,\n",
       "         2555, 9113, 2938, 8116, 6626, 3015, 8323, 5586, 2318, 1358, 4596,  360,\n",
       "         8588, 6427]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.ones(4, 10, dtype=torch.int64)\n",
    "outputs = model(inputs, mode=\"sampling\", k=30, p=0.9)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
